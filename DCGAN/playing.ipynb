{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from models import Generator\n",
    "from models import Discriminator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('C:/Users/david/Documents/Python/data','human_face')\n",
    "batchsize = 32\n",
    "workers = 8\n",
    "nz = 100\n",
    "\n",
    "# folder dataset\n",
    "human_dataset = dset.ImageFolder(root=data_path,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.Resize(64),\n",
    "                            transforms.CenterCrop(64),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                        ]))\n",
    "\n",
    "assert human_dataset\n",
    "human_dataloader = torch.utils.data.DataLoader(human_dataset, batch_size=batchsize,\n",
    "                                        shuffle=True, num_workers=int(workers))\n",
    "\n",
    "# Grab sample. Depending on dataset, may take a while\n",
    "human_iterator = iter(human_dataloader)\n",
    "sample = next(human_iterator)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_vector(img, nz):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.CenterCrop(int(math.sqrt(nz)))\n",
    "    ])\n",
    "    vector = preprocess(img)\n",
    "    # vector = torch.unsqueeze(vector,1)\n",
    "    vector = torch.flatten(vector,start_dim=1,end_dim=3)\n",
    "    return vector[:,:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = image_to_vector(sample,nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = Generator(1,nz,3,64)\n",
    "netG.load_state_dict(torch.load('C:/Users/david/Documents/GitHub/Anime-Portrait-Converter/DCGAN/output/generator_chkpts/netG_epoch_44.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(batchsize, nz, 1, 1)\n",
    "fake = netG(fixed_noise)\n",
    "vutils.save_image(fake.detach(),\n",
    "        'noise_output.png',\n",
    "        normalize=True)\n",
    "\n",
    "fake = netG(vector)\n",
    "vutils.save_image(sample,\n",
    "        'vector_input.png',\n",
    "        normalize=True)\n",
    "vutils.save_image(fake.detach(),\n",
    "        'vector_output.png',\n",
    "        normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Image.open('vector_input.png')\n",
    "input.show()\n",
    "output = Image.open('vector_output.png')\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "674291698da69398d09eaaff8f2d16745172857c9fb6a1cd3dbf75eeb9b95a3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
